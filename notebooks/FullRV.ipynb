{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c652a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/computation/expressions.py:22: UserWarning: Pandas requires version '2.10.2' or newer of 'numexpr' (version '2.8.7' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/masked.py:56: UserWarning: Pandas requires version '1.4.2' or newer of 'bottleneck' (version '1.3.7' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "from RelativeValue import RelativeValue\n",
    "RVStrat = RelativeValue('FX Mexico', '5Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b1e54f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Getting PCA residuals ...\n",
      "Residuals successfully computed\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "RVStrat.get_residuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f548ae13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "STRESS TEST\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Updating tradable tenors...\n",
      "Rebalancing Stress test...\n",
      "Window Stress test...\n",
      "Signal Persistance test...\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "RVStrat.stress_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a456436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "BACKTEST\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  Parameters | Confidence: 0.5 | Buffer: 0.0 | Window: 252 | Volatility Window: 21 | Volatility Target: 21\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "RVStrat.backtest(window=21*12, vol_window=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bc8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import json\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import norm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from Dates import from_excel_date, bump_date\n",
    "from PCA import yield_curve_decomposition\n",
    "\n",
    "# ==========================================\n",
    "# 1. Helper Functions & Utilities\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "def align_pca_signs(res: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Enforces consistent sign orientation for PCA factors to prevent \n",
    "    flipping between rolling windows.\n",
    "    \"\"\"\n",
    "\n",
    "    loadings = res['loadings']\n",
    "    scores = res['scores']\n",
    "    \n",
    "    # 1. Level: Force sum of loadings to be positive (Rates UP = Score UP)\n",
    "    if loadings['Level'].sum() < 0:\n",
    "        loadings['Level'] *= -1\n",
    "        scores['Level'] *= -1\n",
    "\n",
    "    # 2. Slope: Force standard curve shape (10Y > 2Y means Higher Slope Score)\n",
    "    # Check if last tenor loading is greater than first tenor loading\n",
    "    if loadings['Slope'].iloc[-1] < loadings['Slope'].iloc[0]:\n",
    "        loadings['Slope'] *= -1\n",
    "        scores['Slope'] *= -1\n",
    "        \n",
    "    # 3. Curvature: Force \"Humped\" shape (Belly < Wings) for positive score\n",
    "    mid_idx = len(loadings) // 2\n",
    "    if loadings['Curvature'].iloc[mid_idx] > loadings['Curvature'].iloc[0]:\n",
    "         loadings['Curvature'] *= -1\n",
    "         scores['Curvature'] *= -1\n",
    "         \n",
    "    res['loadings'] = loadings\n",
    "    res['scores'] = scores\n",
    "    return res\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# 2. Main Trading Class\n",
    "# ==========================================\n",
    "\n",
    "class FactorTrading:\n",
    "\n",
    "    def __init__(self, country: str, lookback: str = '5Y'):\n",
    "        # Load Config\n",
    "        with open('config.json') as f:\n",
    "            config = json.load(f)[country]\n",
    "        self.tenors = config[\"Tenors\"]\n",
    "\n",
    "        self.rates = pd.read_excel('data/Rates.xlsx', index_col=0, sheet_name=config[\"Curve Name\"])[self.tenors]\n",
    "        self.rates.index.rename('Date', inplace=True)\n",
    "        self.rates.drop('Ticker',inplace=True)\n",
    "        self.rates.index = self.rates.index.map(from_excel_date)\n",
    "        self.rates.index = [d.date() for d in self.rates.index]\n",
    "        self.rates.dropna(inplace=True)\n",
    "        self.rates /= 100\n",
    "            \n",
    "        self.country = country\n",
    "        self.lookback = lookback\n",
    "        self.tenors = config[\"Tenors\"]\n",
    "        self.vol_window = config.get(\"Volatility Window\", 60)\n",
    "        \n",
    "            \n",
    "        self.rates.dropna(inplace=True)\n",
    "        \n",
    "        # Containers for outputs\n",
    "        self.residuals = None\n",
    "        self.pca_scores = None\n",
    "        self.signals = None\n",
    "\n",
    "    def get_residuals(self):\n",
    "        \"\"\"Calculates rolling PCA scores and residuals.\"\"\"\n",
    "        print(f\"=\"*80)\n",
    "        print(f\"Calculating Rolling PCA (Lookback: {self.lookback})...\")\n",
    "\n",
    "        # Determine start date based on lookback from the first available data point\n",
    "        # OR define a simulation start date. Here we process the whole history \n",
    "        # where we have enough data for the lookback.\n",
    "        \n",
    "        # Find first date where we have enough history\n",
    "        first_valid_idx = bump_date(self.rates.index[0], self.lookback)\n",
    "        dates_to_process = self.rates.loc[first_valid_idx:].index\n",
    "\n",
    "        self.residuals = pd.DataFrame(index=dates_to_process, columns=self.rates.columns)\n",
    "        self.pca_scores = pd.DataFrame(index=dates_to_process, columns=['Level', 'Slope', 'Curvature'])\n",
    "        \n",
    "        for d in dates_to_process:\n",
    "            d_date = d.date() if isinstance(d, pd.Timestamp) else d\n",
    "            start_date = bump_date(d_date, '-' + self.lookback)\n",
    "            \n",
    "            # Slice the window\n",
    "            yield_window = self.rates[(self.rates.index >= start_date) & (self.rates.index <= d)]\n",
    "            \n",
    "            if len(yield_window) < 20: # Safety check for enough data\n",
    "                continue\n",
    "\n",
    "            # Decompose\n",
    "            res = yield_curve_decomposition(yield_window)\n",
    "            # *** CRITICAL: Align Signs ***\n",
    "            res = align_pca_signs(res)\n",
    "            \n",
    "            # Store results (taking the last point 'd' from the window)\n",
    "            self.residuals.loc[d] = res['residuals'].iloc[-1]\n",
    "            self.pca_scores.loc[d] = res['scores'].loc[d].values\n",
    "\n",
    "        # Ensure types are float\n",
    "        self.pca_scores = self.pca_scores.astype(float)\n",
    "        self.volatilities = self.pca_scores.diff().rolling(window=21*3).std()\n",
    "        self.normalization_factor = ((1/self.volatilities).div((1/self.volatilities).sum(axis=1), axis='rows'))\n",
    "\n",
    "        print(f\"PCA computation complete. Processed {len(dates_to_process)} dates.\")\n",
    "        print(f\"=\"*80)\n",
    "\n",
    "    def generate_signals(self):\n",
    "        \"\"\"\n",
    "        Generates trading signals based on PCA scores.\n",
    "        \"\"\"\n",
    "        if self.pca_scores is None:\n",
    "            print(\"Error: Run get_residuals() first.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Generating Factor Signals...\")\n",
    "        self.signals = pd.DataFrame(0, index=self.pca_scores.index, columns=['Level', 'Slope', 'Curvature'])\n",
    "        \n",
    "        # --- 1. LEVEL (PC1): Trend Following ---\n",
    "        # Logic: EMA Crossover on the Score\n",
    "        # Note: If aligned correctly, Higher Score = Higher Yields.\n",
    "        # Trend Down in Score = Yields Falling = Bond Price Rising -> Buy Signal\n",
    "        \n",
    "        fast = 30\n",
    "        slow = 90\n",
    "        \n",
    "        level_s = self.pca_scores['Level']\n",
    "        ema_fast = level_s.ewm(span=fast).mean()\n",
    "        ema_slow = level_s.ewm(span=slow).mean()\n",
    "        \n",
    "        # If Fast < Slow (Yields trending down) -> Long Signal (1)\n",
    "        self.signals['Level'] = np.where(ema_fast < ema_slow, 1, -1)\n",
    "\n",
    "        # --- 2. SLOPE (PC2): Carry-Adjusted Mean Reversion ---\n",
    "        # Logic: Fade extremes only if carry is supportive.\n",
    "        \n",
    "        slope_window = 60\n",
    "        slope_s = self.pca_scores['Slope']\n",
    "        z_slope = (slope_s - slope_s.rolling(slope_window).mean()) / slope_s.rolling(slope_window).std()\n",
    "        \n",
    "        # Calculate Carry Proxy (2s10s Spread)\n",
    "        # Using columns by position (usually 10Y is last, 2Y is 2nd or similar)\n",
    "        # Adjust 'iloc' based on your specific 'Tenors' list in config\n",
    "        spread_2s10s = self.rates.iloc[:, -1] - self.rates.iloc[:, 1]\n",
    "        # Align spread index to score index\n",
    "        spread_2s10s = spread_2s10s.reindex(self.pca_scores.index)\n",
    "        \n",
    "        # Thresholds\n",
    "        z_thresh = 1.64\n",
    "        \n",
    "        # Short Slope (Flattening Trade)\n",
    "        # Trigger: Z > 2 (Steep) AND Spread > 0 (Positive Carry to hold flattener/short spread?)\n",
    "        # Note: In rates, \"Short Spread\" usually means Long 10Y, Short 2Y.\n",
    "        # If Spread is Positive (Normal curve), Shorting it usually has Negative Carry (pay high cpn, receive low).\n",
    "        # STRICTLY SPEAKING: Flattener (Long 10Y / Short 2Y) has NEGATIVE carry in normal curve.\n",
    "        # Steepener (Short 10Y / Long 2Y) has POSITIVE carry in normal curve.\n",
    "        # Let's assume you want \"Positive Carry\" for the direction you trade.\n",
    "        \n",
    "        # Let's simplify to pure Z-score for the code, you can refine the carry math:\n",
    "        self.signals.loc[z_slope > z_thresh, 'Slope'] = -1 # Flatten\n",
    "        self.signals.loc[z_slope < -z_thresh, 'Slope'] = 1 # Steepen\n",
    "\n",
    "        # --- 3. CURVATURE (PC3): Mean Reversion ---\n",
    "        # Logic: 2s5s10s Fly. Stationary.\n",
    "        \n",
    "        curv_window = 60\n",
    "        curv_s = self.pca_scores['Curvature']\n",
    "        z_curv = (curv_s - curv_s.rolling(curv_window).mean()) / curv_s.rolling(curv_window).std()\n",
    "        \n",
    "        self.signals.loc[z_curv > 1.64, 'Curvature'] = -1 # Short Fly (Bet on richening/flattening of belly)\n",
    "        self.signals.loc[z_curv < -1.64, 'Curvature'] = 1 # Long Fly\n",
    "        \n",
    "        print(\"Signals generated.\")\n",
    "        print(\"=\"*80)\n",
    "        return self.signals\n",
    "    \n",
    "    def estimate_dv01(self, yield_val, tenor_str):\n",
    "        \"\"\"\n",
    "        Approximates DV01 (Dollar Value of 01) per $1 notional.\n",
    "        Uses Modified Duration approximation for a par bond.\n",
    "        \"\"\"\n",
    "        # Parse tenor to years\n",
    "        if 'Y' in tenor_str:\n",
    "            t = int(tenor_str.replace('Y', ''))\n",
    "        elif 'M' in tenor_str:\n",
    "            t = int(tenor_str.replace('M', '')) / 12\n",
    "        else:\n",
    "            t = 1 # Fallback\n",
    "            \n",
    "        # Mod Duration approx for par bond: (1 - (1+y/f)^(-t*f)) / y\n",
    "        # Using frequency = 1 for simplicity\n",
    "        if yield_val < 0.0001: yield_val = 0.0001 # Avoid div by zero\n",
    "        \n",
    "        m_dur = (1 - (1 + yield_val)**(-t)) / yield_val\n",
    "        \n",
    "        # DV01 = ModDur * Price * 0.0001\n",
    "        # Price approx 1 (Par)\n",
    "        return m_dur * 0.0001\n",
    "\n",
    "    def backtest(self):\n",
    "        \"\"\"\n",
    "        Computes P&L for Level, Slope, and Curvature strategies.\n",
    "        Includes DV01 hedging and Transaction Costs.\n",
    "        \"\"\"\n",
    "        if self.signals is None:\n",
    "            print(\"Run generate_signals() first.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Running Backtest...\")\n",
    "        \n",
    "        # 1. Align Data\n",
    "        # We trade at Close of Day T based on Signal T (or Open of T+1). \n",
    "        # For simplicity: We enter at Close T, realize PnL on T+1 changes.\n",
    "        market_data = self.rates.loc[self.signals.index]\n",
    "        yield_changes = market_data.diff().shift(-1) # return at T+1\n",
    "        yield_changes.dropna(inplace = True)\n",
    "        \n",
    "        # Initialize PnL Series\n",
    "        pnl = pd.DataFrame(0.0, index=self.signals.index, columns=['Level', 'Slope', 'Curvature'])\n",
    "        \n",
    "        # Cost assumptions (in basis points of yield spread)\n",
    "        tc_bps = 0.0\n",
    "        \n",
    "        # Loop through days to calculate dynamic hedge ratios\n",
    "        # (Vectorization is harder here due to changing DV01s)\n",
    "        \n",
    "        for date, row in self.signals.iterrows():\n",
    "            if date not in yield_changes.index: continue\n",
    "            normalization_factors = self.normalization_factor.loc[date]\n",
    "            # Current Yields\n",
    "            y_2y = market_data.loc[date].iloc[1] # Adjust index based on your cols\n",
    "            y_5y = market_data.loc[date].iloc[2] # Adjust index based on your cols\n",
    "            y_10y = market_data.loc[date].iloc[-1]\n",
    "            \n",
    "            # Current DV01s\n",
    "            dv01_2y = self.estimate_dv01(y_2y, \"2Y\")\n",
    "            dv01_5y = self.estimate_dv01(y_5y, \"5Y\")\n",
    "            dv01_10y = self.estimate_dv01(y_10y, \"10Y\")\n",
    "            \n",
    "            # Next Day Yield Change (bps)\n",
    "            dy_2y = yield_changes.loc[date].iloc[1] * 10000\n",
    "            dy_5y = yield_changes.loc[date].iloc[2] * 10000\n",
    "            dy_10y = yield_changes.loc[date].iloc[-1] * 10000\n",
    "            \n",
    "            # --- STRATEGY 1: LEVEL (10Y Only) ---\n",
    "            # Signal: 1 (Long Bonds / Short Yields), -1 (Short Bonds / Long Yields)\n",
    "            sig_lvl = row['Level']*normalization_factors['Level']\n",
    "            # PnL = -Signal * DV01 * Change\n",
    "            # If Signal 1 (Long), Yield Down (Neg Change) -> Positive PnL\n",
    "            pnl.loc[date, 'Level'] = -1 * sig_lvl * dv01_5y * dy_5y\n",
    "            \n",
    "            \n",
    "            # --- STRATEGY 2: SLOPE (2s10s DV01 Neutral) ---\n",
    "            # Signal: 1 (Steepener), -1 (Flattener)\n",
    "            # Steepener: Long 2Y, Short 10Y\n",
    "            sig_slope = row['Slope']*normalization_factors['Slope']\n",
    "            \n",
    "            if sig_slope != 0:\n",
    "                # Hedge Ratio: How many 2Ys for one 10Y?\n",
    "                # ratio * dv01_2y = 1 * dv01_10y\n",
    "                hedge_ratio = dv01_10y / dv01_2y\n",
    "                \n",
    "                # Steepener (1): Long Ratio 2Y, Short 1 Unit 10Y\n",
    "                # Flattener (-1): Short Ratio 2Y, Long 1 Unit 10Y\n",
    "                \n",
    "                leg_2y_pnl = (- sig_slope * hedge_ratio) * (-1 * dv01_2y * dy_2y)\n",
    "                leg_10y_pnl = (sig_slope) * (-1 * dv01_10y * dy_10y)\n",
    "                \n",
    "                pnl.loc[date, 'Slope'] = (leg_2y_pnl + leg_10y_pnl)\n",
    "\n",
    "\n",
    "            # --- STRATEGY 3: CURVATURE (2s5s10s Fly DV01 Neutral) ---\n",
    "            # Signal: 1 (Long Fly: Long Wings, Short Belly), -1 (Short Fly)\n",
    "            # Note: Previously we defined Signal 1 as \"Long Fly\" (Betting on mean reversion).\n",
    "            # Usually Long Fly = Long Wings / Short Belly.\n",
    "            \n",
    "            sig_curv = row['Curvature']*normalization_factors['Curvature']\n",
    "            \n",
    "            if sig_curv != 0:\n",
    "                # Weights: 50% risk in 2Y, 50% risk in 10Y to hedge 1 unit of 5Y\n",
    "                # w_2y * dv01_2y = 0.5 * dv01_5y  -> w_2y = 0.5 * dv01_5y / dv01_2y\n",
    "                # w_10y * dv01_10y = 0.5 * dv01_5y -> w_10y = 0.5 * dv01_5y / dv01_10y\n",
    "                \n",
    "                w_2y = (0.5 * dv01_5y) / dv01_2y\n",
    "                w_10y = (0.5 * dv01_5y) / dv01_10y\n",
    "                \n",
    "                # If Signal 1 (Long Fly): Long w_2y, Long w_10y, Short 1 unit 5Y\n",
    "                dir = sig_curv \n",
    "                \n",
    "                pnl_2y = (-dir * w_2y) * (-1 * dv01_2y * dy_2y)\n",
    "                pnl_10y = (-dir * w_10y) * (-1 * dv01_10y * dy_10y)\n",
    "                pnl_5y = (dir) * (-1 * dv01_5y * dy_5y)\n",
    "                \n",
    "                pnl.loc[date, 'Curvature'] = (pnl_2y + pnl_10y + pnl_5y)\n",
    "\n",
    "        # --- APPLY TRANSACTION COSTS ---\n",
    "        # Calculate Turnover: Absolute change in signal\n",
    "        turnover = self.signals.diff().abs().fillna(0)\n",
    "        \n",
    "        # Cost approximation: Turnover * TC_BPS * Risk_Factor\n",
    "        # We assume 1 unit of risk (approx DV01 of 10Y) for normalization\n",
    "        avg_dv01 = 0.0008 # approx 8 cents per bp\n",
    "        costs = turnover * tc_bps * avg_dv01\n",
    "        \n",
    "        net_pnl = pnl - costs\n",
    "        \n",
    "        print(\"Backtest Complete.\")\n",
    "        \n",
    "        # Cumulative PnL\n",
    "        return net_pnl.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat = FactorTrading(country=\"Chile\", lookback=\"2Y\")\n",
    "\n",
    "# 1. Compute Rolling PCA\n",
    "strat.get_residuals()\n",
    "\n",
    "# 2. Generate Signals\n",
    "sigs = strat.generate_signals()\n",
    "\n",
    "# 3. Backtest\n",
    "pnl = strat.backtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a886175",
   "metadata": {},
   "outputs": [],
   "source": [
    "IL = pnl.sum(axis=1)\n",
    "IL.index = pd.to_datetime(IL.index)\n",
    "IL.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
